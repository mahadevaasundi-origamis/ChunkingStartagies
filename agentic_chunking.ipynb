{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Agentic Chunking with LangChain & watsonx.ai\n",
                "\n",
                "This notebook demonstrates how to use an LLM to dynamically split text into semantically meaningful chunks (Agentic Chunking) to optimize Retrieval Augmented Generation (RAG)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "86106b24",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required package for UnstructuredPDFLoader (use %pip in notebook)\n",
                "%pip install -q unstructured\n",
                "%pip install pdfminer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install Dependencies\n",
                "!pip install -q langchain langchain-ibm langchain_experimental langchain-text-splitters langchain_chroma transformers bs4 langchain_huggingface sentence-transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "1bd558b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Import Libraries\n",
                "\n",
                "# 1. LangChain Core - Base abstractions (Prompt, Messages, Documents)\n",
                "from langchain_core.documents import Document\n",
                "from langchain_core.messages import HumanMessage, SystemMessage\n",
                "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
                "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
                "from langchain_core.tools import tool\n",
                "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
                "\n",
                "\n",
                "# 2. Partner Packages - Specific integrations (The modern way)\n",
                "# specific pip install: langchain-huggingface\n",
                "from langchain_huggingface import HuggingFaceEmbeddings \n",
                "# specific pip install: langchain-chroma\n",
                "from langchain_chroma import Chroma \n",
                "# specific pip install: langchain-ibm\n",
                "from langchain_ibm import WatsonxLLM \n",
                "\n",
                "# 3. LangChain Main - Chains, Agents, and Memory\n",
                "from langchain_classic.agents.agent import (\n",
                "    Agent,\n",
                "    AgentExecutor,\n",
                "    AgentOutputParser,\n",
                "    BaseMultiActionAgent,\n",
                "    BaseSingleActionAgent,\n",
                "    LLMSingleActionAgent,\n",
                ")\n",
                "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
                "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
                "from langchain_classic.memory.buffer import  ConversationBufferMemory\n",
                "\n",
                "# 4. Text Splitters\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "# 5. IBM Watsonx SDK & Transformers (Backend utilities)\n",
                "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
                "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
                "from transformers import AutoTokenizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Step 2: Older Import Libraries\n",
                "import getpass\n",
                "import requests\n",
                "import os\n",
                "from bs4 import BeautifulSoup\n",
                "from dotenv import load_dotenv\n",
                "# from langchain_ibm import WatsonxLLM\n",
                "# from langchain_huggingface import HuggingFaceEmbeddings\n",
                "# from langchain_community.document_loaders import WebBaseLoader\n",
                "# from langchain.schema import SystemMessage, HumanMessage, Document\n",
                "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
                "# from langchain.vectorstores import Chroma\n",
                "# from langchain.tools import tool\n",
                "# from langchain.agents import AgentExecutor\n",
                "# from langchain.memory import ConversationBufferMemory\n",
                "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
                "# from langchain.chains import create_retrieval_chain\n",
                "# from transformers import AutoTokenizer\n",
                "# from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
                "# from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Step 3: Set Up Credentials\n",
                "# # Ensure you have a .env file or manually enter your API key and Project ID below.\n",
                "# load_dotenv(os.getcwd()+\"/.env\", override=True)\n",
                "\n",
                "# credentials = {\n",
                "#     \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
                "#     \"apikey\": os.getenv(\"WATSONX_APIKEY\", \"YOUR_API_KEY_HERE\"),\n",
                "# }\n",
                "# project_id = os.getenv(\"PROJECT_ID\", \"YOUR_PROJECT_ID_HERE\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Step 4: Initialize Language Model (IBM Granite)\n",
                "# llm = WatsonxLLM(\n",
                "#     model_id=\"ibm/granite-3-8b-instruct\",\n",
                "#     url=credentials.get(\"url\"),\n",
                "#     apikey=credentials.get(\"apikey\"),\n",
                "#     project_id=project_id,\n",
                "#     params={\n",
                "#         GenParams.DECODING_METHOD: \"greedy\",\n",
                "#         GenParams.TEMPERATURE: 0,\n",
                "#         GenParams.MIN_NEW_TOKENS: 5,\n",
                "#         GenParams.MAX_NEW_TOKENS: 250,\n",
                "#         GenParams.STOP_SEQUENCES: [\"Human:\", \"Observation\"],\n",
                "#     },\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "66508c37",
            "metadata": {},
            "outputs": [],
            "source": [
                "# First activate wsl\n",
                "!wsl\n",
                "# Then run the ollama gemini-3-pro-preview model in wsl\n",
                "!wsl ollama run gemini-3-pro-preview\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "8da517a2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "I notice that you're asking about \"agentic chunking,\" but that specific term doesn't appear to be a widely recognized concept in mainstream AI or cognitive science. I'd be happy to help, but first I want to clarify what you mean by this term.\n",
                        "\n",
                        "Could you provide more context about where you encountered this phrase or what aspects of it you're interested in? For example, are you referring to:\n",
                        "- Chunking in cognitive psychology?\n",
                        "- Agent-based modeling?\n",
                        "- Task decomposition in AI systems?\n",
                        "- Or perhaps a specific framework or paper you've come across?\n",
                        "\n",
                        "This will help me give you a more accurate and useful explanation.\n"
                    ]
                }
            ],
            "source": [
                "# from langchain_ollama import ChatOllama\n",
                "from langchain_community.llms.ollama import Ollama\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "# 1. Initialize the model pointing to your local Ollama instance\n",
                "# Ollama will handle the bridge to Google's Cloud API automatically\n",
                "llm = Ollama(\n",
                "    # model=\"gemini-3-pro-preview\",\n",
                "    model=\"cogito-2.1:671b-cloud\",\n",
                "    temperature=0.7,\n",
                "    # Optional: Increase context if needed, Gemini 3 supports large windows\n",
                "    num_ctx=32000 \n",
                ")\n",
                "\n",
                "# 2. Create a prompt\n",
                "prompt = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", \"You are a helpful AI assistant.\"),\n",
                "    (\"human\", \"{input}\")\n",
                "])\n",
                "\n",
                "# 3. Create chain\n",
                "chain = prompt | llm\n",
                "\n",
                "# 4. Run\n",
                "response = chain.invoke({\"input\": \"Explain the main advantages of agentic chunking.\"})\n",
                "\n",
                "print(response)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 5: Load Document Function\n",
                "def get_text_from_url(url):\n",
                "    response = requests.get(url)\n",
                "    if response.status_code != 200:\n",
                "        raise ValueError(f\"Failed to fetch the page, status code: {response.status_code}\")\n",
                "    \n",
                "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
                "    for script in soup([\"script\", \"style\"]):\n",
                "        script.decompose()\n",
                "    return soup.get_text(separator=\"\\n\", strip=True)\n",
                "\n",
                "# Load example text\n",
                "url = \"https://www.ibm.com/think/topics/machine-learning\"\n",
                "web_text = get_text_from_url(url)\n",
                "# print(web_text[:500]) # Optional: verify text loaded"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6de43213",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Loaded {len(web_text)} characters from the web page. First 500 characters:\\n{web_text[:500]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1f63078e",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "# Extracting The pdf conetnt using langchain_community which might contain image + text\n",
                "\n",
                "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
                "import os\n",
                "\n",
                "file = r\"files\\Bandhan.pdf\"\n",
                "if not os.path.exists(file):\n",
                "    print(f\"File {file} does not exist. Please check the path.\")\n",
                "else:\n",
                "    print(f\"File {file} found. Proceeding to load.\")\n",
                "\n",
                "\n",
                "loader = UnstructuredPDFLoader(\n",
                "    file_path=file,\n",
                "    mode=\"elements\"\n",
                ")\n",
                "\n",
                "print(f\"loader contents: {loader}\")\n",
                "\n",
                "pages = loader.load()\n",
                "\n",
                "print(f\"Loaded {len(pages)} pages from the PDF document. First page content:\\n{pages[0].page_content[:500]}\")\n",
                "\n",
                "\n",
                "# try:\n",
                "#     data = loader.load()\n",
                "# except ImportError as e:\n",
                "#     # If installation did not take effect in the current kernel, inform the user.\n",
                "#     raise ImportError(\"The 'unstructured' package is required but not available. \"\n",
                "#                       \"Please ensure the cell above ran successfully and then restart the kernel.\") from e\n",
                "\n",
                "print(f\"Loaded {len(data)} pages from the PDF document. First page content:\\n{data[0].page_content[:500]}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "511477c1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "File files\\ES Mod1@AzDOCUMENTS2.pdf found. Proceeding to load.\n"
                    ]
                }
            ],
            "source": [
                "# file from path\n",
                "import os\n",
                "\n",
                "# file_path = r\"files\\Bandhan.pdf\"\n",
                "file_path = r\"files\\ES Mod1@AzDOCUMENTS2.pdf\"\n",
                "if not os.path.exists(file_path):\n",
                "    print(f\"File {file_path} does not exist. Please check the path.\")\n",
                "else:\n",
                "    print(f\"File {file_path} found. Proceeding to load.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "db600637",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 20 pages from the PDF document. First page content:\n",
                        "Embedded Systems-18EC62 \n",
                        "Azdocuments.in\n",
                        "www.azdocuments.in \n",
                        "Page 1 \n",
                        " \n",
                        " \n",
                        " \n",
                        "EMBEDDED SYSTEMS \n",
                        " Course Code : 18EC62 \n",
                        " CIE Marks :40 \n",
                        " Lecture Hours/Week : 03 + 2 (Tutorial) \n",
                        " SEE marks :60 \n",
                        " Total Number of Lecture Hours : 50 (10 Hrs / Module)  \n",
                        " Exam Hours : 03 \n",
                        " CREDITS : 04 \n",
                        "MODULE -1 \n",
                        "ARM-32 bit Microcontroller: Thumb-2 technology and applications of ARM,Architecture of \n",
                        "ARM Cortex M3, Various Units in the architecture, Debuggingsupport, General Purpose \n",
                        "Registers, Special Registers, ex\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.document_loaders import PyMuPDFLoader\n",
                "\n",
                "loader = PyMuPDFLoader(file_path)\n",
                "pages = loader.load()\n",
                "\n",
                "print(f\"Loaded {len(pages)} pages from the PDF document. First page content:\\n{pages[0].page_content[:500]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Chunk 1:\n",
                        "I'll help you split this text into meaningful chunks based on topics. Here's the organized breakdown:\n",
                        "----------------------------------------\n",
                        "Chunk 2:\n",
                        "**Chunk 1: Course Information and Module Overview**\n",
                        "- Embedded Systems course details (18EC62)\n",
                        "- Course structure including marks distribution, credits, and hours\n",
                        "- Module 1 overview: ARM-32 bit Microcontroller topics\n",
                        "----------------------------------------\n",
                        "Chunk 3:\n",
                        "**Chunk 2: Introduction to ARM Cortex-M3**\n",
                        "- Market context for microcontrollers\n",
                        "- ARM Cortex-M3 processor introduction\n",
                        "- Key requirements addressed by Cortex-M3\n",
                        "----------------------------------------\n",
                        "Chunk 4:\n",
                        "**Chunk 3: Features and Benefits of Cortex-M3**\n",
                        "- Performance efficiency\n",
                        "- Low power consumption\n",
                        "- Determinism\n",
                        "- Code density\n",
                        "- Ease of use\n",
                        "- Cost reduction\n",
                        "- Development tools\n",
                        "----------------------------------------\n",
                        "Chunk 5:\n",
                        "**Chunk 4: ARM History and Architecture Versions**\n",
                        "- ARM formation and early history\n",
                        "- Evolution of ARM processors\n",
                        "- ARM architecture versions (v4T to v7)\n",
                        "- Profiles: A, R, and M profiles\n",
                        "----------------------------------------\n",
                        "Chunk 6:\n",
                        "**Chunk 5: Thumb-2 Technology**\n",
                        "- Thumb-2 ISA overview\n",
                        "- Comparison with traditional Thumb\n",
                        "- 16-bit and 32-bit instruction support\n",
                        "- Performance benefits\n",
                        "----------------------------------------\n",
                        "Chunk 7:\n",
                        "**Chunk 6: Cortex-M3 Applications**\n",
                        "- Low-cost microcontrollers\n",
                        "- Automotive applications\n",
                        "- Data communications\n",
                        "- Industrial control\n",
                        "- Consumer products\n",
                        "----------------------------------------\n",
                        "Chunk 8:\n",
                        "**Chunk 7: Cortex-M3 Architecture**\n",
                        "- 32-bit Harvard architecture\n",
                        "- Processor core components\n",
                        "- Memory map overview\n",
                        "- Bus interfaces\n",
                        "----------------------------------------\n",
                        "Chunk 9:\n",
                        "**Chunk 8: Registers in Cortex-M3**\n",
                        "- General purpose registers (R0-R12)\n",
                        "- Stack pointers (MSP, PSP)\n",
                        "- Link register (R14)\n",
                        "- Program counter (R15)\n",
                        "----------------------------------------\n",
                        "Chunk 10:\n",
                        "**Chunk 9: Special Registers and NVIC**\n",
                        "- Program Status Registers\n",
                        "- Interrupt Mask Registers\n",
                        "- Control Register\n",
                        "- Nested Vectored Interrupt Controller features\n",
                        "----------------------------------------\n",
                        "Chunk 11:\n",
                        "**Chunk 10: Memory and Bus Interfaces**\n",
                        "- Predefined memory map\n",
                        "- Bus interfaces (Code memory, System bus, Private peripheral bus)\n",
                        "- Memory Protection Unit (MPU)\n",
                        "----------------------------------------\n",
                        "Chunk 12:\n",
                        "**Chunk 11: Instruction Set**\n",
                        "- Thumb-2 instruction set benefits\n",
                        "- Comparison with ARM/Thumb states\n",
                        "- Key instruction examples\n",
                        "----------------------------------------\n",
                        "Chunk 13:\n",
                        "**Chunk 12: Interrupts and Exceptions**\n",
                        "- Exception model\n",
                        "- Interrupt handling\n",
                        "- Comparison with traditional ARM FIQ\n",
                        "----------------------------------------\n",
                        "Chunk 14:\n",
                        "**Chunk 13: Debugging Support**\n",
                        "- Debug features overview\n",
                        "- Debug Access Port (DAP)\n",
                        "- Trace capabilities\n",
                        "- JTAG and Serial-Wire interfaces\n",
                        "----------------------------------------\n",
                        "Chunk 15:\n",
                        "**Chunk 14: Stack Operations**\n",
                        "- Stack PUSH and POP operations\n",
                        "- Software stack usage\n",
                        "- Stack implementation details\n",
                        "----------------------------------------\n",
                        "Chunk 16:\n",
                        "**Chunk 15: Reset Sequence**\n",
                        "- Processor reset behavior\n",
                        "- Initial stack pointer and program counter\n",
                        "- Vector table initialization\n",
                        "- Example reset sequence\n",
                        "----------------------------------------\n",
                        "Chunk 17:\n",
                        "**Chunk 16: Review Questions**\n",
                        "- List of recommended questions for study\n",
                        "- Covers all major topics in the document\n",
                        "----------------------------------------\n",
                        "Chunk 18:\n",
                        "This organization groups related concepts together while maintaining the logical flow of information from the original document.\n",
                        "----------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Step 6: Agentic Chunking Function\n",
                "def agentic_chunking(text):\n",
                "    \"\"\"\n",
                "    Dynamically splits text into meaningful chunks using LLM.\n",
                "    \"\"\"\n",
                "    system_message = SystemMessage(content=\"You are an AI assistant helping to split text into meaningful chunks based on topics.\")\n",
                "    human_message = HumanMessage(content=f\"Please divide the following text into semantically different, separate and meaningful chunks:\\n\\n{text}\")\n",
                "    \n",
                "    # Invoke LLM\n",
                "    response = llm.invoke([system_message, human_message])\n",
                "    return response.split(\"\\n\\n\") # Split based on meaningful sections\n",
                "\n",
                "# Execute chunking\n",
                "chunks = agentic_chunking(pages)\n",
                "\n",
                "# Print chunks\n",
                "for i, chunk in enumerate(chunks, 1):\n",
                "    print(f\"Chunk {i}:\\n{chunk}\\n{'-'*40}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 7: Create Vector Store and RAG Chain\n",
                "\n",
                "# Initialize Embeddings\n",
                "embeddings_model = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-30m-english\")\n",
                "\n",
                "# Create Vector Database\n",
                "vector_db = Chroma(\n",
                "    collection_name=\"example_collection\",\n",
                "    embedding_function=embeddings_model\n",
                ")\n",
                "\n",
                "# Add Documents\n",
                "documents = [Document(page_content=chunk) for chunk in chunks]\n",
                "vector_db.add_documents(documents)\n",
                "\n",
                "# Create RAG Chain\n",
                "prompt_template = \"\"\"<|start_of_role|>user<|end_of_role|>Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
                "{context}\n",
                "Question: {input}<|end_of_text|>\n",
                "<|start_of_role|>assistant<|end_of_role|>\"\"\"\n",
                "\n",
                "qa_chain_prompt = PromptTemplate.from_template(prompt_template)\n",
                "combine_docs_chain = create_stuff_documents_chain(llm, qa_chain_prompt)\n",
                "rag_chain = create_retrieval_chain(vector_db.as_retriever(), combine_docs_chain)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The ARM Cortex-M3 processor is widely used across various applications due to its efficient performance, low power consumption, and cost-effectiveness. Key application areas include:\n",
                        "\n",
                        "1. **Low-cost microcontrollers**: Ideal for cost-sensitive embedded systems where performance and power efficiency are crucial.\n",
                        "\n",
                        "2. **Automotive applications**: Used in automotive control systems, body electronics, and sensor interfaces due to its reliability and determinism.\n",
                        "\n",
                        "3. **Data communications**: Supports communication protocols and network interfaces in networking equipment.\n",
                        "\n",
                        "4. **Industrial control**: Employed in automation systems, motor control, and real-time monitoring due to its deterministic behavior and robustness.\n",
                        "\n",
                        "5. **Consumer products**: Found in devices like home appliances, wearables, and IoT devices, benefiting from its low power consumption and ease of integration.\n",
                        "\n",
                        "These applications leverage the Cortex-M3's 32-bit Harvard architecture, efficient code density, and comprehensive development tools.\n"
                    ]
                }
            ],
            "source": [
                "# Step 8: Execute RAG Query\n",
                "rag_output = rag_chain.invoke({\"input\": \"Write a short note on the applicatios of Cortex-M3 \"})\n",
                "print(rag_output['answer'])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
