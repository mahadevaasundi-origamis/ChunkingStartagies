{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b393be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chonkie in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-experimental in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (2.12.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: unstructured in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (0.18.20)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from chonkie) (4.67.1)\n",
      "Requirement already satisfied: numpy>=2.0.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from chonkie) (2.2.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (1.0.7)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (0.4.44)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: filetype in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (6.0.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (3.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (4.14.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (2.15.0)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (2025.11.16)\n",
      "Requirement already satisfied: langdetect in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (3.14.3)\n",
      "Requirement already satisfied: backoff in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (0.42.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (1.17.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (7.1.3)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from tqdm>=4.64.0->chonkie) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from beautifulsoup4->unstructured) (2.8)\n",
      "Requirement already satisfied: webencodings in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from nltk->unstructured) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from nltk->unstructured) (1.5.2)\n",
      "Requirement already satisfied: olefile in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured-client->unstructured) (25.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured-client->unstructured) (46.0.3)\n",
      "Requirement already satisfied: pypdf>=6.2.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from unstructured-client->unstructured) (6.3.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mahadevaa\\onedrive - cxio technologies pvt ltd\\documents\\github\\research\\chunkingstartagies\\venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=3.1->unstructured-client->unstructured) (2.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chonkie langchain-community langchain-ollama langchain-experimental faiss-cpu pandas pydantic tiktoken pyarrow unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725f8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "from typing import List, Optional, Dict, Any, Literal\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- 1. Metadata Schema (Strict Pydantic Model) ---\n",
    "class ChunkMetadata(BaseModel):\n",
    "    doc_id: str\n",
    "    chunk_id: str\n",
    "    source_path: str\n",
    "    mime_type: str\n",
    "    page_number: Optional[int] = None\n",
    "    bbox: Optional[List[float]] = None # [x1, y1, x2, y2]\n",
    "    section_title: Optional[str] = \"General\"\n",
    "    content_type: Literal[\"narrative\", \"tabular\", \"code\", \"markdown\"]\n",
    "    token_count: int\n",
    "    hash_sha256: str\n",
    "    vector_metric: str = \"cosine\"\n",
    "    embedding_model: str\n",
    "    table_schema: Optional[str] = None # For tabular chunks\n",
    "    neighbors: List[str] = [] # IDs of adjacent chunks\n",
    "    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "class Chunk(BaseModel):\n",
    "    text: str\n",
    "    tokens: List[int]\n",
    "    start_char: int\n",
    "    end_char: int\n",
    "    metadata: ChunkMetadata\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "EMBEDDING_MODEL_NAME = \"nomic-embed-text\" # Run `ollama pull nomic-embed-text`\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "TOKEN_ENCODING = \"cl100k_base\" # Standard for many LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eaca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Embeddings...\n",
      "Processing Complete. Outputs saved to output/\n"
     ]
    }
   ],
   "source": [
    "from chonkie import TokenChunker, RecursiveChunker, SemanticChunker\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "\n",
    "class AgenticChunkingOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = tiktoken.get_encoding(TOKEN_ENCODING)\n",
    "        self.embedder = OllamaEmbeddings(\n",
    "            model=EMBEDDING_MODEL_NAME, \n",
    "            base_url=OLLAMA_URL\n",
    "        )\n",
    "        self.chunks_buffer: List[Chunk] = []\n",
    "        self.report_log: List[str] = []\n",
    "\n",
    "    def _compute_hash(self, text: str) -> str:\n",
    "        return hashlib.sha256(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        return len(self.tokenizer.encode(text))\n",
    "\n",
    "    # --- STRATEGY ROUTER ---\n",
    "    def determine_strategy(self, file_path: str, content_sample: str) -> str:\n",
    "        \"\"\"\n",
    "        Agentic decision making based on file extension and content signals.\n",
    "        \"\"\"\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        # 1. Code/Markdown Check\n",
    "        if ext in ['.md', '.py', '.js', '.json', '.yaml']:\n",
    "            return \"recursive_markdown\"\n",
    "        \n",
    "        # 2. Tabular Check (CSV or Excel)\n",
    "        if ext in ['.csv', '.xlsx', '.parquet']:\n",
    "            return \"tabular_row\"\n",
    "\n",
    "        # 3. Narrative Check (PDFs, Docx, TXT)\n",
    "        # Simple heuristic: specific keywords or lack of code symbols\n",
    "        if \"table of contents\" in content_sample.lower() or len(content_sample) > 1000:\n",
    "            return \"semantic_narrative\"\n",
    "            \n",
    "        return \"token_fallback\"\n",
    "\n",
    "    # --- CHUNKING ENGINES ---\n",
    "    def process_document(self, file_path: str, text_content: str, doc_id: str):\n",
    "        strategy = self.determine_strategy(file_path, text_content[:2000])\n",
    "        self.report_log.append(f\"Doc: {doc_id} | Strategy: {strategy}\")\n",
    "        \n",
    "        raw_chunks = []\n",
    "        \n",
    "        # Strategy 1: Narrative (Semantic)\n",
    "        if strategy == \"semantic_narrative\":\n",
    "            # Chonkie Semantic Chunker (presuming similarity thresholding)\n",
    "            chunker = SemanticChunker(\n",
    "                embedding_model=self.embedder, \n",
    "                threshold=0.75, \n",
    "                chunk_size=512\n",
    "            )\n",
    "            raw_chunks = chunker.chunk(text_content)\n",
    "\n",
    "        # Strategy 2: Code/Markdown (Recursive)\n",
    "        elif strategy == \"recursive_markdown\":\n",
    "            chunker = RecursiveChunker(\n",
    "                chunk_size=1024,\n",
    "                # chunk_overlap=100 # ~10% overlap\n",
    "            )\n",
    "            raw_chunks = chunker.chunk(text_content)\n",
    "\n",
    "        # Strategy 3: Tabular (Custom Logic)\n",
    "        elif strategy == \"tabular_row\":\n",
    "            # Basic CSV row grouping simulation\n",
    "            rows = text_content.split('\\n')\n",
    "            headers = rows[0]\n",
    "            # Group every 5 rows to maintain context\n",
    "            current_chunk = []\n",
    "            for row in rows[1:]:\n",
    "                current_chunk.append(row)\n",
    "                if len(current_chunk) >= 5:\n",
    "                    raw_chunks.append(f\"Schema: {headers}\\nData:\\n\" + \"\\n\".join(current_chunk))\n",
    "                    current_chunk = []\n",
    "            if current_chunk:\n",
    "                raw_chunks.append(f\"Schema: {headers}\\nData:\\n\" + \"\\n\".join(current_chunk))\n",
    "\n",
    "        # Strategy 4: Fallback\n",
    "        else:\n",
    "            chunker = TokenChunker()\n",
    "            raw_chunks = chunker.chunk(text_content)\n",
    "\n",
    "        # --- ENRICHMENT PHASE ---\n",
    "        self._enrich_and_store(raw_chunks, doc_id, file_path, strategy)\n",
    "\n",
    "    def _enrich_and_store(self, raw_chunks: List[Any], doc_id: str, source: str, strategy: str):\n",
    "        total_chunks = len(raw_chunks)\n",
    "        \n",
    "        for i, chunk_obj in enumerate(raw_chunks):\n",
    "            # Handle Chonkie object vs string\n",
    "            text = chunk_obj.text if hasattr(chunk_obj, 'text') else str(chunk_obj)\n",
    "            start = chunk_obj.start_index if hasattr(chunk_obj, 'start_index') else 0\n",
    "            end = chunk_obj.end_index if hasattr(chunk_obj, 'end_index') else 0\n",
    "            \n",
    "            token_ids = self.tokenizer.encode(text)\n",
    "            count = len(token_ids)\n",
    "            \n",
    "            # Generate ID: doc_id:chunk_index\n",
    "            chunk_id = f\"{doc_id}:ch_{i}\"\n",
    "            \n",
    "            # Identify Neighbors\n",
    "            prev_id = f\"{doc_id}:ch_{i-1}\" if i > 0 else None\n",
    "            next_id = f\"{doc_id}:ch_{i+1}\" if i < total_chunks - 1 else None\n",
    "            neighbors = list(filter(None, [prev_id, next_id]))\n",
    "\n",
    "            meta = ChunkMetadata(\n",
    "                doc_id=doc_id,\n",
    "                chunk_id=chunk_id,\n",
    "                source_path=source,\n",
    "                mime_type=\"text/plain\", # Simplified for demo\n",
    "                content_type=\"tabular\" if \"tabular\" in strategy else \"narrative\",\n",
    "                token_count=count,\n",
    "                hash_sha256=self._compute_hash(text),\n",
    "                embedding_model=EMBEDDING_MODEL_NAME,\n",
    "                vector_metric=\"cosine\",\n",
    "                neighbors=neighbors\n",
    "            )\n",
    "            final_chunk = Chunk(\n",
    "                text=text,\n",
    "                tokens=token_ids,\n",
    "                start_char=start,\n",
    "                end_char=end,\n",
    "                metadata=meta\n",
    "            )\n",
    "            self.chunks_buffer.append(final_chunk)\n",
    "\n",
    "    # --- PERSISTENCE & INDEXING ---\n",
    "    def save_results(self, output_dir=\"output\"):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. JSONL Store\n",
    "        jsonl_path = f\"{output_dir}/chunks.jsonl\"\n",
    "        with open(jsonl_path, 'w') as f:\n",
    "            for ch in self.chunks_buffer:\n",
    "                f.write(ch.model_dump_json() + \"\\n\")\n",
    "        \n",
    "        # 2. Parquet Store (Metadata only for fast scanning)\n",
    "        meta_dicts = [ch.metadata.model_dump() for ch in self.chunks_buffer]\n",
    "        df = pd.DataFrame(meta_dicts)\n",
    "        df.to_parquet(f\"{output_dir}/chunk_metadata.parquet\")\n",
    "\n",
    "        # 3. Vector Indexing (FAISS)\n",
    "        print(\"Generating Embeddings...\")\n",
    "        texts = [ch.text for ch in self.chunks_buffer]\n",
    "        metadatas = [ch.metadata.model_dump() for ch in self.chunks_buffer]\n",
    "        \n",
    "        # Initialize FAISS with Cosine Similarity (Normalize L2)\n",
    "        vectorstore = FAISS.from_texts(\n",
    "            texts=texts,\n",
    "            embedding=self.embedder,\n",
    "            metadatas=metadatas,\n",
    "            docstore=InMemoryDocstore(),\n",
    "            index_to_docstore_id={}\n",
    "        )\n",
    "        vectorstore.save_local(f\"{output_dir}/faiss_index\")\n",
    "\n",
    "        # 4. Report\n",
    "        with open(f\"{output_dir}/chunking_report.md\", \"w\") as f:\n",
    "            f.write(\"# Chunking Strategy Report\\n\\n\")\n",
    "            f.write(f\"**Total Chunks:** {len(self.chunks_buffer)}\\n\")\n",
    "            f.write(\"## Operations Log\\n\")\n",
    "            for log in self.report_log:\n",
    "                f.write(f\"- {log}\\n\")\n",
    "\n",
    "        print(f\"Processing Complete. Outputs saved to {output_dir}/\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Mock Data Creation for Demonstration\n",
    "    sample_text = \"\"\"\n",
    "    # Agentic RAG\n",
    "    RAG systems require smart chunking. \n",
    "    \n",
    "    ## Strategy\n",
    "    1. Semantic chunking is best for stories.\n",
    "    2. Recursive is best for code.\n",
    "    \"\"\"\n",
    "    \n",
    "    orchestrator = AgenticChunkingOrchestrator()\n",
    "    orchestrator.process_document(\"manual.md\", sample_text, \"doc_001\")\n",
    "    orchestrator.save_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
